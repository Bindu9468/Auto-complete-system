{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To build an auto-complete system. Auto-complete system is something you may see every day:\n",
    "\n",
    "When you google something, you often have suggestions to help you complete\n",
    "your search.\n",
    "When you are writing an email, you get suggestions telling you possible endings\n",
    "to your sentence.\n",
    "\n",
    "Develop the prototype of such a system.\n",
    "\n",
    "Q1.1 Load and Preprocess Data\n",
    "\n",
    "Q1.2 Develop n-gram based language models \n",
    "\n",
    "Q1.3 Perplexity \n",
    "\n",
    "Q1.4 Build an auto-complete system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Bindu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.data.path.append('.')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data.\n",
    "\n",
    "This section involves working with Twitter data. Begin by loading the data and examining the first few sentences. The data consists of a long string containing numerous tweets, with each tweet separated by a line break (\"\\n\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: <class 'str'>\n",
      "Number of letters: 3335477\n",
      "First 30 letters of the data\n",
      "-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How are you? Btw thanks for th'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "Last 30 letters of the data\n",
      "-------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' after 5 was a TERRIBLE idea.\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n"
     ]
    }
   ],
   "source": [
    "with open('C:\\\\Users\\\\Bindu\\\\Documents\\\\NLP\\\\twitter.txt','r',encoding='utf-8') as f:\n",
    "    data=f.read()\n",
    "print(\"Data type:\", type(data))\n",
    "print(\"Number of letters:\", len(data))\n",
    "print(\"First 30 letters of the data\")\n",
    "print(\"-------\")\n",
    "display(data[0:30])\n",
    "print(\"-------\")\n",
    "\n",
    "print(\"Last 30 letters of the data\")\n",
    "print(\"-------\")\n",
    "display(data[-30:])\n",
    "print(\"-------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process the Data\n",
    "\n",
    "To pre-process the Twitter data, follow these steps:\n",
    "\n",
    "1. **Split the data into sentences**: Use the line break (`\"\\n\"`) as the delimiter to separate the data into individual sentences.\n",
    "2. **Tokenize each sentence**: Split each sentence into tokens (words). In this context, \"tokens\" and \"words\" are used interchangeably.\n",
    "3. **Assign sentences to train or test sets**: Divide the sentences into training and testing datasets.\n",
    "4. **Identify common tokens**: Find tokens that appear at least \\( N \\) times in the training data.\n",
    "5. **Replace rare tokens**: Replace tokens that appear less than \\( N \\) times with the `<unk>` marker.\n",
    "\n",
    "Note: Validation data is omitted for simplicity in this exercise. In real-world applications, a validation set would typically be used to tune the model during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE1-SPLIT THE DATA INTO SENTENCES\n",
    "\n",
    "\n",
    "\n",
    "**Hint**: Use the `str.split` method to split the data into sentences based on the `\"\\n\"` delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello !\n",
      "my name is siri\n",
      "['hello !', 'my name is siri']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_to_sentences(data):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!|\\n)\\s', data)\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    sentences = [s for s in sentences if len(s) > 0]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "x = \"hello !\\nmy name is siri\"\n",
    "print(x)\n",
    "print(split_to_sentences(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE2-TOKENIZING GIVEN SENTENCE\n",
    "\n",
    "\n",
    "The next step involves tokenizing the sentences, which means splitting each sentence into a list of words. Follow these steps:\n",
    "\n",
    "Convert Tokens to Lowercase: Convert all tokens to lowercase to ensure that words capitalized at the start of a sentence are treated the same as their lowercase versions.\n",
    "\n",
    "Tokenize Sentences: Use nltk.word_tokenize to split each sentence into tokens. This approach handles punctuation and edge cases more effectively than str.split.\n",
    "\n",
    "Append Tokenized Sentences: Collect each list of tokenized words into a larger list of tokenized sentences.\n",
    "\n",
    "Hints:\n",
    "\n",
    "Use str.lower to convert strings to lowercase.\n",
    "Use nltk.word_tokenize to handle tokenization properly and account for punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hey', 'there', ',', 'what', \"'s\", 'up', '?'], ['hello', ',', 'how', 'are', 'you', '?'], ['call', 'sir', 'to', 'take', 'classes', '.']]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sentences(sentences):\n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        lowercase_sentence = sentence.lower() \n",
    "        tokens = word_tokenize(lowercase_sentence)  \n",
    "        result.append(tokens)\n",
    "    return result\n",
    "\n",
    "sentences = [\"Hey there, what's up?\", \"HELLO, how are you?\", \"Call sir to take classes.\"]\n",
    "print(tokenize_sentences(sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE3-TRAINING AND TESTING DATA\n",
    "\n",
    "To split the data into training and test sets, you can follow these general steps. Here's a sample code snippet to achieve this:\n",
    "\n",
    "Determine the Split Ratio: Decide how to split the data (e.g., 80% training, 20% testing).\n",
    "\n",
    "Shuffle the Data: Shuffle the list of tokenized sentences to ensure randomness.\n",
    "\n",
    "Split the Data: Divide the shuffled list into training and test sets based on the chosen ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.'], ['python', 'is', 'a', 'powerful', 'programming', 'language', '.'], ['data', 'science', 'is', 'an', 'exciting', 'field', '.']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_tokenized_data(data):\n",
    "    sentences = data.split(\"\\n\")\n",
    "    tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    \n",
    "    return tokenized_sentences\n",
    "x = \"The quick brown fox jumps over the lazy dog.\\nPython is a powerful programming language.\\nData science is an exciting field.\"\n",
    "tokenized_data = get_tokenized_data(x)\n",
    "print(tokenized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47962 data are split into 38369 train and 9593 test set\n",
      "First training sample:\n",
      "['i', '‚ù§', 'and', 'her', 'boo', 'relationship', 'they', 'so', 'thuged', 'out', '!', '!']\n",
      "First test sample\n",
      "['better', 'than', '``', 'misplaced', 'quotation', 'marks', \"''\", 'rt', ':', 'lately', 'i', 'find', 'that', 'i', 'am', 'adding', 'too', 'many', 'exclamation', 'points', 'where', 'they', 'do', \"n't\", 'belong', '!']\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = get_tokenized_data(data)\n",
    "random.seed(87)\n",
    "random.shuffle(tokenized_data)\n",
    "\n",
    "train_size = int(len(tokenized_data) * 0.8)\n",
    "train_data = tokenized_data[0:train_size]\n",
    "test_data = tokenized_data[train_size:]\n",
    "print(\"{} data are split into {} train and {} test set\".format(\n",
    "    len(tokenized_data), len(train_data), len(test_data)))\n",
    "\n",
    "print(\"First training sample:\")\n",
    "print(train_data[0])\n",
    "      \n",
    "print(\"First test sample\")\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE4 - WORD COUNT IN SENTENCES\n",
    "\n",
    "\n",
    "In this exercise, the goal is to focus on words that appear at least N times in the data. This involves counting the frequency of each word and filtering out words that don't meet the frequency threshold.\n",
    "\n",
    "Here‚Äôs how to approach this:\n",
    "\n",
    "Count Word Frequencies:\n",
    "\n",
    "Use a double for-loop to count how many times each word appears in the data.\n",
    "Filter Words:\n",
    "\n",
    "Keep only those words that appear at least N times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies: {'hello': 2, 'world': 2, '.': 2, 'welcome': 1, 'to': 1, 'the': 1, 'of': 1, 'programming': 1, 'again': 1, '!': 1}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def count_words(tokenized_sentences):\n",
    "    word_counts = defaultdict(int)\n",
    "    for sentence in tokenized_sentences:\n",
    "        for word in sentence:\n",
    "            word_counts[word] += 1\n",
    "    return dict(word_counts)\n",
    "x = \"Hello world.\\nWelcome to the world of programming.\\nHello again!\"\n",
    "tokenized_sentences = get_tokenized_data(x)\n",
    "word_freq = count_words(tokenized_sentences)\n",
    "\n",
    "print(\"Word Frequencies:\", word_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Out-of-Vocabulary (OOV) Words\n",
    "\n",
    "When building an autocomplete model, encountering a word that wasn‚Äôt seen during training presents a challenge. This \"unknown\" word, or out-of-vocabulary (OOV) word, makes it difficult for the model to predict the next word since there are no counts for it.\n",
    "\n",
    "To address this issue, use a special token, such as `'unk'`, to represent all unknown words. Here‚Äôs how to modify the training data to handle OOV words:\n",
    "\n",
    "1. **Identify Frequent Words**: Determine which words appear frequently in the training data. These words will form the \"closed vocabulary.\"\n",
    "\n",
    "2. **Replace Rare Words**: Convert all words that are not in the closed vocabulary to the token `'unk'`.\n",
    "\n",
    "3. **Calculate the OOV Rate**: The percentage of words in the test set that are unknown or replaced with `'unk'` is called the OOV rate.\n",
    "\n",
    "By following these steps, the model can handle unknown words more effectively during prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE5 - COUNT_THRESHOLD AND CLOSED VOCALUBULARY\n",
    "\n",
    "To create a function that identifies and returns a closed vocabulary list based on a count threshold, follow these steps:\n",
    "\n",
    "Count Word Frequencies: First, count the frequency of each word in the text document.\n",
    "\n",
    "Filter Words: Keep only those words whose count is greater than or equal to the specified threshold.\n",
    "Return the Closed Vocabulary: Return the list of words that meet the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Vocabulary:\n",
      "['.', 'are']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_words_with_nplus_frequency(tokenized_sentences, count_threshold):\n",
    "    word_counts = count_words(tokenized_sentences)\n",
    "    closed_vocab = [word for word, count in word_counts.items() if count >= count_threshold]\n",
    "    return closed_vocab\n",
    "tokenized_sentences = [['sky', 'is', 'blue', '.'],\n",
    "                       ['leaves', 'are', 'green', '.'],\n",
    "                       ['roses', 'are', 'red', '.']]\n",
    "min_count = 2\n",
    "closed_vocab = get_words_with_nplus_frequency(tokenized_sentences, min_count)\n",
    "\n",
    "print(\"Closed Vocabulary:\")\n",
    "print(closed_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE6 - CLOSED VOCABULARY CREATION: WORDS APPEARING AT LEAST COUNT_THRESHOLD TIMES\n",
    "\n",
    "HANDLING UNKNOWN WORDS: REPLACING NON-CLOSED VOCABULARY WORDS WITH unk\n",
    "\n",
    "To replace words not in the closed vocabulary with the token <unk>, follow these steps:\n",
    "\n",
    "Identify Closed Vocabulary: Determine which words appear at least count_threshold times.\n",
    "\n",
    "Replace Unknown Words: For words not in the closed vocabulary, replace them with <unk>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      "[['dogs', 'run'], ['cats', 'sleep']]\n",
      "tokenized_sentences with less frequent words converted to '<unk>':\n",
      "[['dogs', '<unk>'], ['<unk>', 'sleep']]\n"
     ]
    }
   ],
   "source": [
    "def  replace_out_of_vocab_tokens(tokenized_sentences, vocabulary, unknown_token=\"<unk>\"):\n",
    "    vocabulary = set(vocabulary)\n",
    "    replaced_tokenized_sentences = []\n",
    "    \n",
    "    \n",
    "    for sentence in tokenized_sentences:\n",
    "        replaced_sentence = []\n",
    "       \n",
    "        for token in sentence:\n",
    "            if token in vocabulary:\n",
    "                replaced_sentence.append(token)\n",
    "            else:\n",
    "    \n",
    "                replaced_sentence.append(unknown_token)\n",
    "        \n",
    "        \n",
    "        replaced_tokenized_sentences.append(replaced_sentence)\n",
    "        \n",
    "    return replaced_tokenized_sentences\n",
    "\n",
    "\n",
    "tokenized_sentences = [[\"dogs\", \"run\"], [\"cats\", \"sleep\"]]\n",
    "vocabulary = [\"dogs\", \"sleep\"]\n",
    "print(\"Original sentence:\")\n",
    "print(tokenized_sentences)\n",
    "print(\"tokenized_sentences with less frequent words converted to '<unk>':\")\n",
    "print( replace_out_of_vocab_tokens(tokenized_sentences, vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Sentences with '<unk>':\n",
      "[['apple', 'banana', 'apple', '<unk>', 'banana', '<unk>', 'apple', 'banana', '<unk>'], ['cat', '<unk>', '<unk>']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "example_sentences = [\n",
    "    ['apple', 'banana', 'apple', 'grape', 'banana', 'fruit', 'apple', 'banana', 'fruit'],\n",
    "    ['cat', 'chases', 'mouse']\n",
    "]\n",
    "\n",
    "\n",
    "vocabulary = ['apple', 'banana', 'cat']\n",
    "\n",
    "updated_sentences = replace_out_of_vocab_tokens(example_sentences, vocabulary)\n",
    "\n",
    "print(\"Processed Sentences with '<unk>':\")\n",
    "print(updated_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE7 - PROCESSING DATA: COMBINING FUNCTIONS TO HANDLE UNKNOWN TOKENS\n",
    "\n",
    "To process the data, follow these steps:\n",
    "\n",
    "Identify Closed Vocabulary: Find tokens in the training data that appear at least count_threshold times.\n",
    "\n",
    "Replace Unknown Tokens: Replace tokens that appear less frequently than count_threshold in both the training and test data with unk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_train_repl\n",
      "[['water', 'is', 'blue', '.'], ['trees', 'are', 'green']]\n",
      "\n",
      "tmp_test_repl\n",
      "[['<unk>', 'are', '<unk>', '.']]\n",
      "\n",
      "tmp_vocab\n",
      "['water', 'is', 'blue', '.', 'trees', 'are', 'green']\n"
     ]
    }
   ],
   "source": [
    "def process_and_replace_tokens(train_sentences, test_sentences, count_threshold):\n",
    "  \n",
    "    vocab = get_words_with_nplus_frequency(train_sentences, count_threshold)\n",
    "    \n",
    "    train_sentences_replaced = replace_out_of_vocab_tokens(train_sentences, vocab)\n",
    "    \n",
    "    test_sentences_replaced = replace_out_of_vocab_tokens(test_sentences, vocab)\n",
    "    \n",
    "    return train_sentences_replaced, test_sentences_replaced, vocab\n",
    "\n",
    "tmp_train = [['water', 'is', 'blue', '.'],\n",
    "             ['trees', 'are', 'green']]\n",
    "\n",
    "tmp_test = [['lips', 'are', 'pick', '.']]\n",
    "\n",
    "tmp_train_repl, tmp_test_repl, tmp_vocab = process_and_replace_tokens(tmp_train, tmp_test, count_threshold=1)\n",
    "\n",
    "print(\"tmp_train_repl\")\n",
    "print(tmp_train_repl)\n",
    "print()\n",
    "print(\"tmp_test_repl\")\n",
    "print(tmp_test_repl)\n",
    "print()\n",
    "print(\"tmp_vocab\")\n",
    "print(tmp_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To preprocess the train and test data, you need to run the preprocess_data function with the appropriate minimum_freq and then print the results. Here‚Äôs a step-by-step guide on how to achieve this:\n",
    "\n",
    "Define the preprocess_data function: Ensure you have the preprocess_data, get_words_with_nplus_frequency, and replace_oov_words_by_unk functions defined and working correctly.\n",
    "\n",
    "Preprocess the data: Call the preprocess_data function with your training and test datasets along with the minimum_freq value.\n",
    "\n",
    "Print the results: Display the first preprocessed training sample, the first preprocessed test sample, the first 10 vocabulary words, and the size of the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First preprocessed training sample:\n",
      "['i', '‚ù§', 'and', 'her', 'boo', 'relationship', 'they', 'so', '<unk>', 'out', '!', '!']\n",
      "\n",
      "First preprocessed test sample:\n",
      "['better', 'than', '``', 'misplaced', '<unk>', 'marks', \"''\", 'rt', ':', 'lately', 'i', 'find', 'that', 'i', 'am', 'adding', 'too', 'many', 'exclamation', 'points', 'where', 'they', 'do', \"n't\", 'belong', '!']\n",
      "\n",
      "First 10 vocabulary:\n",
      "['i', '‚ù§', 'and', 'her', 'boo', 'relationship', 'they', 'so', 'out', '!']\n",
      "\n",
      "Size of vocabulary: 14931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "minimum_freq = 2\n",
    "train_data_processed, test_data_processed, vocabulary = process_and_replace_tokens(train_data, test_data, minimum_freq)\n",
    "\n",
    "print(\"First preprocessed training sample:\")\n",
    "print(train_data_processed[0])\n",
    "print()\n",
    "print(\"First preprocessed test sample:\")\n",
    "print(test_data_processed[0])\n",
    "print()\n",
    "print(\"First 10 vocabulary:\")\n",
    "print(vocabulary[0:10])\n",
    "print()\n",
    "print(\"Size of vocabulary:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have completed the preprocessing phase of the assignment. The objects train_data_processed, test_data_processed, and vocabulary will be utilized in the subsequent exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Develop n-gram based language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE8 - IMPLEMENTING FUNCTION THAT COMPUTES THE N-GRAMS OF ARBITRARY NUMBER N.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll implement a function to compute the counts of n-grams for any value of \\( n \\).\n",
    "\n",
    "When calculating the counts for n-grams, first prepare the sentence by adding starting markers \\<s \\> at the beginning to signify the start of the sentence.\n",
    "\n",
    "For instance, in a bigram model (N=2), you should prepend two start tokens \\< s > \\<s > to predict the first word of the sentence. Thus, if the sentence is \\\"I like food\\\"\\, modify it to \\<s>\\<s> I like food\\\". Also, append an end token \\ <e> to signal the end of the sentence, allowing the model to know when to conclude.\n",
    "\n",
    "Technically, you'll store these counts in a dictionary where:\n",
    "- The key is a tuple of n words (instead of a list).\n",
    "- The value is the count of occurrences of this n-gram.\n",
    "\n",
    "Using a tuple as the key is preferable because tuples are immutable and thus suitable for dictionary keys, whereas lists are mutable and not allowed as dictionary keys.\n",
    "\n",
    "Hints:\n",
    "- To prepend or append tokens, you can create lists and concatenate them using the `+` operator.\n",
    "- To create a list with repeated values, use syntax like `['a'] * 3` to generate `['a', 'a', 'a']`.\n",
    "- To determine the range for index 'i', consider this example: For a bigram model (n=2) with a sentence length of N=5 (including two start tokens and one end token), the valid index positions are [0, 1, 2, 3, 4]. The largest index 'i' for starting a bigram is 3, as the words at positions 3 and 4 form the bigram.\n",
    "\n",
    "Remember, the `range()` function excludes the maximum value; for example, `range(3)` produces (0, 1, 2) but does not include 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uni-gram:\n",
      "{('i',): 1, ('like',): 2, ('a',): 2, ('cat',): 2, ('<e>',): 2, ('this',): 1, ('dog',): 1, ('is',): 1}\n",
      "Bi-gram:\n",
      "{('<s>', 'i'): 1, ('i', 'like'): 1, ('like', 'a'): 2, ('a', 'cat'): 2, ('cat', '<e>'): 2, ('<s>', 'this'): 1, ('this', 'dog'): 1, ('dog', 'is'): 1, ('is', 'like'): 1}\n"
     ]
    }
   ],
   "source": [
    "def count_n_grams(data, n, start_token='<s>', end_token='<e>'):\n",
    "  \n",
    "    n_grams = {}\n",
    "\n",
    "    for sentence in data:\n",
    "        \n",
    "        sentence = [start_token] * (n - 1) + sentence + [end_token]\n",
    "      \n",
    "        sentence = tuple(sentence)  \n",
    "       \n",
    "        for i in range(len(sentence) - n + 1):\n",
    "            \n",
    "            n_gram = sentence[i:i + n]\n",
    "           \n",
    "            if n_gram in n_grams:\n",
    "              \n",
    "                n_grams[n_gram] += 1\n",
    "            else:\n",
    "                \n",
    "                n_grams[n_gram] = 1\n",
    "    \n",
    "    return n_grams\n",
    "\n",
    "\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "print(\"Uni-gram:\")\n",
    "print(count_n_grams(sentences, 1))\n",
    "print(\"Bi-gram:\")\n",
    "print(count_n_grams(sentences, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE9 - ESTIMATE THE PROBABILITY OF THE WORD GIVEN THE PRIOR 'N' WORDS USING N-GRAM COUNTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are additional hints:\n",
    "\n",
    "- To define a tuple with just one value, include a comma after the value. For example, `('apple',)` is a tuple containing a single string `'apple'`.\n",
    "- To concatenate two tuples, use the `+` operator. For example, `('apple',) + ('banana',)` results in `('apple', 'banana')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probability of word 'cat' given the previous n-gram 'a' is: 0.3333\n"
     ]
    }
   ],
   "source": [
    "def estimate_probability(word, previous_n_gram, \n",
    "                         n_gram_counts, n_plus1_gram_counts, vocabulary_size, k=1.0):\n",
    "   \n",
    "    previous_n_gram = tuple(previous_n_gram)\n",
    "    \n",
    "   \n",
    "    previous_n_gram_count = n_gram_counts.get(previous_n_gram, 0)\n",
    "    denominator = previous_n_gram_count + k * vocabulary_size\n",
    "\n",
    "    n_plus1_gram = previous_n_gram + (word,)\n",
    "  \n",
    "   \n",
    "    n_plus1_gram_count = n_plus1_gram_counts.get(n_plus1_gram, 0)\n",
    "        \n",
    "  \n",
    "  \n",
    "    numerator = n_plus1_gram_count + k\n",
    "\n",
    "    probability = numerator / denominator\n",
    "\n",
    "    \n",
    "    return probability\n",
    "\n",
    "\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "tmp_prob = estimate_probability(\"cat\", [\"a\"], unigram_counts, bigram_counts, len(unique_words), k=1)\n",
    "\n",
    "print(f\"The estimated probability of word 'cat' given the previous n-gram 'a' is: {tmp_prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate probabilities for all words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined below loops over all words in vocabulary to calculate probabilities for all possible words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.09090909090909091,\n",
       " 'i': 0.09090909090909091,\n",
       " 'like': 0.09090909090909091,\n",
       " 'this': 0.09090909090909091,\n",
       " 'dog': 0.09090909090909091,\n",
       " 'cat': 0.2727272727272727,\n",
       " 'is': 0.09090909090909091,\n",
       " '<e>': 0.09090909090909091,\n",
       " '<unk>': 0.09090909090909091}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def estimate_probabilities(previous_n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary, k=1.0):\n",
    "   \n",
    "    previous_n_gram = tuple(previous_n_gram)\n",
    "  \n",
    "    vocabulary = vocabulary + [\"<e>\", \"<unk>\"]\n",
    "    vocabulary_size = len(vocabulary)\n",
    "    \n",
    "    probabilities = {}\n",
    "    for word in vocabulary:\n",
    "        probability = estimate_probability(word, previous_n_gram, \n",
    "                                           n_gram_counts, n_plus1_gram_counts, \n",
    "                                           vocabulary_size, k=k)\n",
    "        probabilities[word] = probability\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "estimate_probabilities(\"a\", unigram_counts, bigram_counts, unique_words, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.1111111111111111,\n",
       " 'i': 0.2222222222222222,\n",
       " 'like': 0.1111111111111111,\n",
       " 'this': 0.2222222222222222,\n",
       " 'dog': 0.1111111111111111,\n",
       " 'cat': 0.1111111111111111,\n",
       " 'is': 0.1111111111111111,\n",
       " '<e>': 0.1111111111111111,\n",
       " '<unk>': 0.1111111111111111}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trigram_counts = count_n_grams(sentences, 3)\n",
    "estimate_probabilities([\"<s>\", \"<s>\"], bigram_counts, trigram_counts, unique_words, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count and probability matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've discussed, the n-gram counts computed are adequate for calculating the probabilities of the next word.\n",
    "\n",
    "To make these probabilities more intuitive, they can be presented as count or probability matrices. The functions provided in the following cells will return these matrices. This function has already been provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram counts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>like</th>\n",
       "      <th>this</th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "      <th>is</th>\n",
       "      <th>&lt;e&gt;</th>\n",
       "      <th>&lt;unk&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(a,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(cat,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(like,)</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(dog,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(is,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(this,)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           a    i  like  this  dog  cat   is  <e>  <unk>\n",
       "(a,)     0.0  0.0   0.0   0.0  0.0  2.0  0.0  0.0    0.0\n",
       "(cat,)   0.0  0.0   0.0   0.0  0.0  0.0  0.0  2.0    0.0\n",
       "(like,)  2.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0    0.0\n",
       "(dog,)   0.0  0.0   0.0   0.0  0.0  0.0  1.0  0.0    0.0\n",
       "(<s>,)   0.0  1.0   0.0   1.0  0.0  0.0  0.0  0.0    0.0\n",
       "(is,)    0.0  0.0   1.0   0.0  0.0  0.0  0.0  0.0    0.0\n",
       "(i,)     0.0  0.0   1.0   0.0  0.0  0.0  0.0  0.0    0.0\n",
       "(this,)  0.0  0.0   0.0   0.0  1.0  0.0  0.0  0.0    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_count_matrix(n_plus1_gram_counts, vocabulary):\n",
    "\n",
    "    vocabulary = vocabulary + [\"<e>\", \"<unk>\"]\n",
    "    \n",
    "    n_grams = []\n",
    "    for n_plus1_gram in n_plus1_gram_counts.keys():\n",
    "        n_gram = n_plus1_gram[0:-1]\n",
    "        n_grams.append(n_gram)\n",
    "    n_grams = list(set(n_grams))\n",
    "    \n",
    "  \n",
    "    row_index = {n_gram:i for i, n_gram in enumerate(n_grams)}\n",
    "   \n",
    "    col_index = {word:j for j, word in enumerate(vocabulary)}\n",
    "    \n",
    "    nrow = len(n_grams)\n",
    "    ncol = len(vocabulary)\n",
    "    count_matrix = np.zeros((nrow, ncol))\n",
    "    for n_plus1_gram, count in n_plus1_gram_counts.items():\n",
    "        n_gram = n_plus1_gram[0:-1]\n",
    "        word = n_plus1_gram[-1]\n",
    "        if word not in vocabulary:\n",
    "            continue\n",
    "        i = row_index[n_gram]\n",
    "        j = col_index[word]\n",
    "        count_matrix[i, j] = count\n",
    "    \n",
    "    count_matrix = pd.DataFrame(count_matrix, index=n_grams, columns=vocabulary)\n",
    "    return count_matrix\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "                 ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "\n",
    "print('bigram counts')\n",
    "display(make_count_matrix(bigram_counts, unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trigram counts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>like</th>\n",
       "      <th>this</th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "      <th>is</th>\n",
       "      <th>&lt;e&gt;</th>\n",
       "      <th>&lt;unk&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, &lt;s&gt;)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(this, dog)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, i)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(dog, is)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(&lt;s&gt;, this)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(is, like)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, like)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(a, cat)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(like, a)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               a    i  like  this  dog  cat   is  <e>  <unk>\n",
       "(<s>, <s>)   0.0  1.0   0.0   1.0  0.0  0.0  0.0  0.0    0.0\n",
       "(this, dog)  0.0  0.0   0.0   0.0  0.0  0.0  1.0  0.0    0.0\n",
       "(<s>, i)     0.0  0.0   1.0   0.0  0.0  0.0  0.0  0.0    0.0\n",
       "(dog, is)    0.0  0.0   1.0   0.0  0.0  0.0  0.0  0.0    0.0\n",
       "(<s>, this)  0.0  0.0   0.0   0.0  1.0  0.0  0.0  0.0    0.0\n",
       "(is, like)   1.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0    0.0\n",
       "(i, like)    1.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0    0.0\n",
       "(a, cat)     0.0  0.0   0.0   0.0  0.0  0.0  0.0  2.0    0.0\n",
       "(like, a)    0.0  0.0   0.0   0.0  0.0  2.0  0.0  0.0    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\ntrigram counts')\n",
    "trigram_counts = count_n_grams(sentences, 3)\n",
    "display(make_count_matrix(trigram_counts, unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram probabilities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>like</th>\n",
       "      <th>this</th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "      <th>is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a         i      like      this       dog       cat        is\n",
       "a     0.111111  0.111111  0.111111  0.111111  0.111111  0.333333  0.111111\n",
       "cat   0.142857  0.142857  0.142857  0.142857  0.142857  0.142857  0.142857\n",
       "like  0.333333  0.111111  0.111111  0.111111  0.111111  0.111111  0.111111\n",
       "dog   0.125000  0.125000  0.125000  0.125000  0.125000  0.125000  0.250000\n",
       "<s>   0.111111  0.222222  0.111111  0.222222  0.111111  0.111111  0.111111\n",
       "is    0.125000  0.125000  0.250000  0.125000  0.125000  0.125000  0.125000\n",
       "i     0.125000  0.125000  0.250000  0.125000  0.125000  0.125000  0.125000\n",
       "this  0.125000  0.125000  0.125000  0.125000  0.250000  0.125000  0.125000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram probabilities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>i</th>\n",
       "      <th>like</th>\n",
       "      <th>this</th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "      <th>is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <th>dog</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>i</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>this</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>like</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>cat</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <th>a</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  a         i      like      this       dog       cat  \\\n",
       "<s>  <s>   0.111111  0.222222  0.111111  0.222222  0.111111  0.111111   \n",
       "this dog   0.125000  0.125000  0.125000  0.125000  0.125000  0.125000   \n",
       "<s>  i     0.125000  0.125000  0.250000  0.125000  0.125000  0.125000   \n",
       "dog  is    0.125000  0.125000  0.250000  0.125000  0.125000  0.125000   \n",
       "<s>  this  0.125000  0.125000  0.125000  0.125000  0.250000  0.125000   \n",
       "is   like  0.250000  0.125000  0.125000  0.125000  0.125000  0.125000   \n",
       "i    like  0.250000  0.125000  0.125000  0.125000  0.125000  0.125000   \n",
       "a    cat   0.142857  0.142857  0.142857  0.142857  0.142857  0.142857   \n",
       "like a     0.111111  0.111111  0.111111  0.111111  0.111111  0.333333   \n",
       "\n",
       "                 is  \n",
       "<s>  <s>   0.111111  \n",
       "this dog   0.250000  \n",
       "<s>  i     0.125000  \n",
       "dog  is    0.125000  \n",
       "<s>  this  0.125000  \n",
       "is   like  0.125000  \n",
       "i    like  0.125000  \n",
       "a    cat   0.142857  \n",
       "like a     0.111111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def make_count_matrix(n_plus1_gram_counts, vocabulary):\n",
    "   \n",
    "    n_gram_keys = list(set([n_gram[:-1] for n_gram in n_plus1_gram_counts.keys()]))\n",
    "    \n",
    "    \n",
    "    count_matrix = pd.DataFrame(0, index=pd.MultiIndex.from_tuples(n_gram_keys), columns=vocabulary)\n",
    "\n",
    "  \n",
    "    for n_plus1_gram, count in n_plus1_gram_counts.items():\n",
    "        n_gram = n_plus1_gram[:-1]\n",
    "        word = n_plus1_gram[-1]    \n",
    "        if n_gram in count_matrix.index and word in count_matrix.columns:\n",
    "            count_matrix.at[n_gram, word] = count\n",
    "\n",
    "    return count_matrix\n",
    "\n",
    "def make_probability_matrix(n_plus1_gram_counts, vocabulary, k):\n",
    "  \n",
    "    count_matrix = make_count_matrix(n_plus1_gram_counts, vocabulary)\n",
    "    \n",
    "\n",
    "    count_matrix += k\n",
    "    \n",
    "   \n",
    "    prob_matrix = count_matrix.div(count_matrix.sum(axis=1), axis=0)\n",
    "    return prob_matrix\n",
    "\n",
    "def count_n_grams(sentences, n):\n",
    "    n_gram_counts = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        sentence = ['<s>'] * (n-1) + sentence + ['</s>'] \n",
    "        n_grams = zip(*[sentence[i:] for i in range(n)])\n",
    "        for n_gram in n_grams:\n",
    "            n_gram_counts[n_gram] += 1\n",
    "    return n_gram_counts\n",
    "\n",
    "\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "print(\"Bigram probabilities\")\n",
    "bigram_prob_matrix = make_probability_matrix(bigram_counts, unique_words, k=1)\n",
    "display(bigram_prob_matrix)\n",
    "\n",
    "trigram_counts = count_n_grams(sentences, 3)\n",
    "print(\"Trigram probabilities\")\n",
    "trigram_prob_matrix = make_probability_matrix(trigram_counts, unique_words, k=1)\n",
    "display(trigram_prob_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the probabilities are, the lower the perplexity will be.\n",
    "\n",
    "The more the n-grams tell us about the sentence, the lower the perplexity score will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE 10 - Compute the perplexity score given an N-gram count matrix and a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity for first train sample: 3.2293\n",
      "Perplexity for test sample: 3.8027\n"
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(sentence, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k=1.0):\n",
    "    \n",
    "    n = len(list(n_gram_counts.keys())[0]) \n",
    "    \n",
    "   \n",
    "    sentence = [\"<s>\"] * n + sentence + [\"<e>\"]\n",
    "    \n",
    "   \n",
    "    N = len(sentence)\n",
    "    \n",
    "    \n",
    "    product_pi = 1.0\n",
    "    \n",
    "    \n",
    "    for t in range(n, N):\n",
    "        \n",
    "        n_gram = tuple(sentence[t-n:t])\n",
    "        \n",
    "       \n",
    "        word = sentence[t]\n",
    "        \n",
    "        \n",
    "        probability = estimate_probability(word, n_gram, n_gram_counts, n_plus1_gram_counts, vocabulary_size, k=k)\n",
    "        \n",
    "       \n",
    "        product_pi *= 1 / probability\n",
    "\n",
    "  \n",
    "    perplexity = product_pi ** (1 / N)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "\n",
    "perplexity_train1 = calculate_perplexity(sentences[0],\n",
    "                                         unigram_counts, bigram_counts,\n",
    "                                         len(unique_words), k=1.0)\n",
    "print(f\"Perplexity for first train sample: {perplexity_train1:.4f}\")\n",
    "\n",
    "test_sentence = ['i', 'like', 'a', 'dog']\n",
    "perplexity_test = calculate_perplexity(test_sentence,\n",
    "                                       unigram_counts, bigram_counts,\n",
    "                                       len(unique_words), k=1.0)\n",
    "print(f\"Perplexity for test sample: {perplexity_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Build an auto-complete system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11- Compute probabilities for all possible next words and suggest the most likely one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the probabilities for all potential next words and identify the most likely one.\n",
    "\n",
    "This function also accepts an optional argument, `start_with`, which specifies the initial letters of the next words.\n",
    "\n",
    "Hints:\n",
    "- `estimate_probabilities` returns a dictionary where each key is a word, and the corresponding value is the probability of that word.\n",
    "- Use `str1.startswith(str2)` to check if a string begins with the specified letters. For example, `'learning'.startswith('lea')` returns `True`, while `'learning'.startswith('ear')` returns `False`. You can use the default values for the additional parameters of `str.startswith()` in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are 'i like',\n",
      "\tand the suggested word is `a` with a probability of 0.2727\n",
      "\n",
      "The previous words are 'i like', the suggestion must start with `c`\n",
      "\tand the suggested word is `cat` with a probability of 0.0909\n"
     ]
    }
   ],
   "source": [
    "def suggest_a_word(previous_tokens, n_gram_counts, n_plus1_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    \n",
    "    n = len(list(n_gram_counts.keys())[0]) \n",
    "    \n",
    "   \n",
    "    previous_n_gram = previous_tokens[-n:]\n",
    "\n",
    "    probabilities = estimate_probabilities(previous_n_gram,\n",
    "                                           n_gram_counts, n_plus1_gram_counts,\n",
    "                                           vocabulary, k=k)\n",
    "   \n",
    "    suggestion = None\n",
    "    max_prob = 0\n",
    "    \n",
    "    for word, prob in probabilities.items():  \n",
    "      \n",
    "        if start_with:  \n",
    "            if not word.startswith(start_with):\n",
    "                continue\n",
    "        \n",
    "        if prob > max_prob:\n",
    "            suggestion = word\n",
    "            \n",
    "            max_prob = prob\n",
    "    return suggestion, max_prob\n",
    "\n",
    "\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "\n",
    "previous_tokens = [\"i\", \"like\"]\n",
    "tmp_suggest1 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0)\n",
    "print(f\"The previous words are 'i like',\\n\\tand the suggested word is `{tmp_suggest1[0]}` with a probability of {tmp_suggest1[1]:.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "tmp_starts_with = 'c'\n",
    "tmp_suggest2 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0, start_with=tmp_starts_with)\n",
    "print(f\"The previous words are 'i like', the suggestion must start with `{tmp_starts_with}`\\n\\tand the suggested word is `{tmp_suggest2[0]}` with a probability of {tmp_suggest2[1]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get multiple suggestions\n",
    "The function defined below loop over varioud n-gram models to get multiple suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are 'i like', the suggestions are:\n",
      "Suggested word: a, Probability: 0.2727\n",
      "Suggested word: a, Probability: 0.2000\n",
      "Suggested word: a, Probability: 0.1111\n",
      "Suggested word: a, Probability: 0.1111\n"
     ]
    }
   ],
   "source": [
    "def get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=None):\n",
    "    \n",
    "    model_counts = len(n_gram_counts_list)\n",
    "    suggestions = []\n",
    "    for i in range(model_counts - 1):\n",
    "        n_gram_counts = n_gram_counts_list[i]\n",
    "        n_plus1_gram_counts = n_gram_counts_list[i + 1]\n",
    "        \n",
    "        suggestion = suggest_a_word(previous_tokens, n_gram_counts,\n",
    "                                    n_plus1_gram_counts, vocabulary,\n",
    "                                    k=k, start_with=start_with)\n",
    "        suggestions.append(suggestion)\n",
    "    return suggestions\n",
    "\n",
    "\n",
    "def count_n_grams(sentences, n):\n",
    "    \n",
    "    n_grams = {}\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence)\n",
    "        for i in range(sentence_length - n + 1):\n",
    "            n_gram = tuple(sentence[i:i + n])\n",
    "            if n_gram in n_grams:\n",
    "                n_grams[n_gram] += 1\n",
    "            else:\n",
    "                n_grams[n_gram] = 1\n",
    "    return n_grams\n",
    "\n",
    "sentences = [['i', 'like', 'a', 'cat'],\n",
    "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
    "unique_words = list(set(sentences[0] + sentences[1]))\n",
    "\n",
    "unigram_counts = count_n_grams(sentences, 1)\n",
    "bigram_counts = count_n_grams(sentences, 2)\n",
    "trigram_counts = count_n_grams(sentences, 3)\n",
    "quadgram_counts = count_n_grams(sentences, 4)\n",
    "qintgram_counts = count_n_grams(sentences, 5)\n",
    "\n",
    "n_gram_counts_list = [unigram_counts, bigram_counts, trigram_counts, quadgram_counts, qintgram_counts]\n",
    "previous_tokens = [\"i\", \"like\"]\n",
    "tmp_suggest3 = get_suggestions(previous_tokens, n_gram_counts_list, unique_words, k=1.0)\n",
    "\n",
    "print(f\"The previous words are 'i like', the suggestions are:\")\n",
    "for suggestion in tmp_suggest3:\n",
    "    print(f\"Suggested word: {suggestion[0]}, Probability: {suggestion[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams of varying lengths (unigrams, bigrams, trigrams, 4-grams...6-grams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing n-gram counts with n = 1 ...\n",
      "Computing n-gram counts with n = 2 ...\n",
      "Computing n-gram counts with n = 3 ...\n",
      "Computing n-gram counts with n = 4 ...\n",
      "Computing n-gram counts with n = 5 ...\n",
      "The previous words are ['i', 'am', 'to'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('go', 0.11764705882352941),\n",
       " ('want', 0.06666666666666667),\n",
       " ('want', 0.06666666666666667),\n",
       " ('want', 0.06666666666666667)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are ['i', 'want', 'to', 'go'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('want', 0.0625), ('want', 0.0625), ('want', 0.0625), ('want', 0.0625)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are ['hey', 'how', 'are'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('you', 0.17647058823529413),\n",
       " ('you', 0.17647058823529413),\n",
       " ('you', 0.125),\n",
       " ('want', 0.06666666666666667)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are ['hey', 'how', 'are', 'you'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doing', 0.11764705882352941),\n",
       " ('doing', 0.11764705882352941),\n",
       " ('doing', 0.11764705882352941),\n",
       " ('want', 0.0625)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous words are ['hey', 'how', 'are', 'you'], the suggestions are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doing', 0.11764705882352941),\n",
       " ('doing', 0.11764705882352941),\n",
       " ('doing', 0.11764705882352941),\n",
       " ('doing', 0.0625)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display  # Use this in Jupyter Notebook\n",
    "\n",
    "def count_n_grams(sentences, n):\n",
    "    \n",
    "    n_grams = {}\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence)\n",
    "        for i in range(sentence_length - n + 1):\n",
    "            n_gram = tuple(sentence[i:i + n])\n",
    "            if n_gram in n_grams:\n",
    "                n_grams[n_gram] += 1\n",
    "            else:\n",
    "                n_grams[n_gram] = 1\n",
    "    return n_grams\n",
    "\n",
    "\n",
    "train_data_processed = [\n",
    "    ['i', 'am', 'happy'],\n",
    "    ['i', 'want', 'to', 'go'],\n",
    "    ['how', 'are', 'you', 'doing'],\n",
    "    ['i', 'am', 'going', 'to', 'school'],\n",
    "    ['hey', 'how', 'are', 'you']\n",
    "]\n",
    "\n",
    "vocabulary = list(set([word for sentence in train_data_processed for word in sentence]))\n",
    "\n",
    "\n",
    "n_gram_counts_list = []\n",
    "for n in range(1, 6):\n",
    "    print(\"Computing n-gram counts with n =\", n, \"...\")\n",
    "    n_model_counts = count_n_grams(train_data_processed, n)\n",
    "    n_gram_counts_list.append(n_model_counts)\n",
    "\n",
    "previous_tokens_list = [\n",
    "    [\"i\", \"am\", \"to\"],\n",
    "    [\"i\", \"want\", \"to\", \"go\"],\n",
    "    [\"hey\", \"how\", \"are\"],\n",
    "    [\"hey\", \"how\", \"are\", \"you\"]\n",
    "]\n",
    "\n",
    "for previous_tokens in previous_tokens_list:\n",
    "    suggestions = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0)\n",
    "    print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
    "    display(suggestions)\n",
    "\n",
    "\n",
    "previous_tokens = [\"hey\", \"how\", \"are\", \"you\"]\n",
    "suggestions_with_start = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=\"d\")\n",
    "print(f\"The previous words are {previous_tokens}, the suggestions are:\")\n",
    "display(suggestions_with_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS - WHICH HAS BEST ACCURACY?             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating accuracy for n-gram model with n = 1...\n",
      "Context: ('i',), True Next Word: am, Suggestions: []\n",
      "Context: ('i', 'am'), True Next Word: happy, Suggestions: []\n",
      "Context: ('i',), True Next Word: want, Suggestions: []\n",
      "Context: ('i', 'want'), True Next Word: to, Suggestions: []\n",
      "Context: ('i', 'want', 'to'), True Next Word: go, Suggestions: []\n",
      "Context: ('how',), True Next Word: are, Suggestions: []\n",
      "Context: ('how', 'are'), True Next Word: you, Suggestions: []\n",
      "Context: ('how', 'are', 'you'), True Next Word: doing, Suggestions: []\n",
      "Context: ('i',), True Next Word: am, Suggestions: []\n",
      "Context: ('i', 'am'), True Next Word: going, Suggestions: []\n",
      "Context: ('i', 'am', 'going'), True Next Word: to, Suggestions: []\n",
      "Context: ('i', 'am', 'going', 'to'), True Next Word: school, Suggestions: []\n",
      "Context: ('hey',), True Next Word: how, Suggestions: []\n",
      "Context: ('hey', 'how'), True Next Word: are, Suggestions: []\n",
      "Context: ('hey', 'how', 'are'), True Next Word: you, Suggestions: []\n",
      "Evaluating accuracy for n-gram model with n = 2...\n",
      "Context: ('i',), True Next Word: am, Suggestions: ['am', 'want']\n",
      "Context: ('i', 'am'), True Next Word: happy, Suggestions: ['happy']\n",
      "Context: ('i',), True Next Word: want, Suggestions: ['am', 'want']\n",
      "Context: ('i', 'want'), True Next Word: to, Suggestions: ['to']\n",
      "Context: ('i', 'want', 'to'), True Next Word: go, Suggestions: ['go']\n",
      "Context: ('how',), True Next Word: are, Suggestions: ['are']\n",
      "Context: ('how', 'are'), True Next Word: you, Suggestions: ['you']\n",
      "Context: ('how', 'are', 'you'), True Next Word: doing, Suggestions: ['doing']\n",
      "Context: ('i',), True Next Word: am, Suggestions: ['am', 'want']\n",
      "Context: ('i', 'am'), True Next Word: going, Suggestions: ['happy']\n",
      "Context: ('i', 'am', 'going'), True Next Word: to, Suggestions: []\n",
      "Context: ('i', 'am', 'going', 'to'), True Next Word: school, Suggestions: ['go']\n",
      "Context: ('hey',), True Next Word: how, Suggestions: ['how']\n",
      "Context: ('hey', 'how'), True Next Word: are, Suggestions: ['are']\n",
      "Context: ('hey', 'how', 'are'), True Next Word: you, Suggestions: ['you']\n",
      "Evaluating accuracy for n-gram model with n = 3...\n",
      "Context: ('i',), True Next Word: am, Suggestions: []\n",
      "Context: ('i', 'am'), True Next Word: happy, Suggestions: ['happy']\n",
      "Context: ('i',), True Next Word: want, Suggestions: []\n",
      "Context: ('i', 'want'), True Next Word: to, Suggestions: []\n",
      "Context: ('i', 'want', 'to'), True Next Word: go, Suggestions: []\n",
      "Context: ('how',), True Next Word: are, Suggestions: []\n",
      "Context: ('how', 'are'), True Next Word: you, Suggestions: ['you']\n",
      "Context: ('how', 'are', 'you'), True Next Word: doing, Suggestions: ['doing']\n",
      "Context: ('i',), True Next Word: am, Suggestions: []\n",
      "Context: ('i', 'am'), True Next Word: going, Suggestions: ['happy']\n",
      "Context: ('i', 'am', 'going'), True Next Word: to, Suggestions: []\n",
      "Context: ('i', 'am', 'going', 'to'), True Next Word: school, Suggestions: []\n",
      "Context: ('hey',), True Next Word: how, Suggestions: []\n",
      "Context: ('hey', 'how'), True Next Word: are, Suggestions: []\n",
      "Context: ('hey', 'how', 'are'), True Next Word: you, Suggestions: ['you']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  Accuracy\n",
       "0  1  0.000000\n",
       "1  2  0.800000\n",
       "2  3  0.266667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Example implementation of get_suggestions\n",
    "def get_suggestions(previous_tokens, n_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    suggestions = []\n",
    "    n = len(next(iter(n_gram_counts.keys())))\n",
    "    for n_gram, count in n_gram_counts.items():\n",
    "        if len(n_gram) == n and previous_tokens[-(n-1):] == list(n_gram[:-1]):\n",
    "            if start_with is None or n_gram[-1].startswith(start_with):\n",
    "                suggestions.append(n_gram[-1])\n",
    "    return suggestions\n",
    "\n",
    "def evaluate_accuracy(n_gram_counts, test_data):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for sentence in test_data:\n",
    "        for i in range(len(sentence) - 1):\n",
    "            context = tuple(sentence[:i+1])\n",
    "            true_next_word = sentence[i+1]\n",
    "            \n",
    "            suggestions = get_suggestions(list(context), n_gram_counts, vocabulary, k=1.0)\n",
    "            print(f\"Context: {context}, True Next Word: {true_next_word}, Suggestions: {suggestions}\")\n",
    "            \n",
    "            if true_next_word in suggestions:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Test data\n",
    "test_data = [\n",
    "    ['i', 'am', 'happy'],\n",
    "    ['i', 'want', 'to', 'go'],\n",
    "    ['how', 'are', 'you', 'doing'],\n",
    "    ['i', 'am', 'going', 'to', 'school'],\n",
    "    ['hey', 'how', 'are', 'you']\n",
    "]\n",
    "\n",
    "# Example n-gram counts list (replace with actual counts)\n",
    "n_gram_counts_list = [\n",
    "    {('i',): 5, ('am',): 4, ('happy',): 2, ('want',): 3, ('to',): 5, ('go',): 2, ('how',): 3, ('are',): 4, ('you',): 5, ('doing',): 1, ('going',): 2, ('school',): 1, ('hey',): 2},\n",
    "    {('i', 'am'): 4, ('am', 'happy'): 2, ('i', 'want'): 2, ('want', 'to'): 2, ('to', 'go'): 2, ('how', 'are'): 3, ('are', 'you'): 3, ('you', 'doing'): 1, ('i', 'am', 'going'): 1, ('am', 'going', 'to'): 1, ('going', 'to', 'school'): 1, ('hey', 'how'): 2, ('how', 'are'): 2},\n",
    "    {('i', 'am', 'happy'): 2, ('am', 'happy', 'to'): 1, ('happy', 'to', 'go'): 1, ('to', 'go', 'to'): 1, ('go', 'to', 'school'): 1, ('how', 'are', 'you'): 3, ('are', 'you', 'doing'): 1, ('you', 'doing', 'well'): 1, ('i', 'am', 'going', 'to'): 1, ('am', 'going', 'to', 'school'): 1},\n",
    "    # Add actual counts for n=4, n=5, etc.\n",
    "]\n",
    "\n",
    "# Evaluate each n-gram model\n",
    "accuracy_results = []\n",
    "for n, n_gram_counts in enumerate(n_gram_counts_list, start=1):\n",
    "    print(f\"Evaluating accuracy for n-gram model with n = {n}...\")\n",
    "    accuracy = evaluate_accuracy(n_gram_counts, test_data)\n",
    "    accuracy_results.append({'n': n, 'Accuracy': accuracy})\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "display(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentences from the dataset:\n",
      "['How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way', 'too', 'long.']\n",
      "['When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for', 'no', 'reason.']\n",
      "[\"they've\", 'decided', 'its', 'more', 'fun', 'if', 'I', \"don't.\"]\n",
      "['So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5', 'Minutes', ';)']\n",
      "['Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even', 'better', ':)']\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip().split() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:\\\\Users\\\\Bindu\\\\Documents\\\\NLP\\\\twitter.txt'\n",
    "data = load_data(file_path)\n",
    "\n",
    "# Print a few sentences to check\n",
    "print(\"Sample sentences from the dataset:\")\n",
    "for sentence in data[:5]:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(previous_tokens, n_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    suggestions = []\n",
    "    n = len(next(iter(n_gram_counts.keys())))\n",
    "    for n_gram, count in n_gram_counts.items():\n",
    "        if len(n_gram) == n and previous_tokens[-(n-1):] == list(n_gram[:-1]):\n",
    "            if start_with is None or n_gram[-1].startswith(start_with):\n",
    "                suggestions.append(n_gram[-1])\n",
    "    return suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating n-gram counts for n = 1...\n",
      "Generating n-gram counts for n = 2...\n",
      "Generating n-gram counts for n = 3...\n",
      "Generating n-gram counts for n = 4...\n",
      "Generating n-gram counts for n = 5...\n",
      "Evaluating accuracy for n-gram model with n = 1...\n",
      "Evaluating accuracy for n-gram model with n = 2...\n",
      "Evaluating accuracy for n-gram model with n = 3...\n",
      "Evaluating accuracy for n-gram model with n = 4...\n",
      "Evaluating accuracy for n-gram model with n = 5...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.870130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  Accuracy\n",
       "0  1  0.000000\n",
       "1  2  1.000000\n",
       "2  3  0.935065\n",
       "3  4  0.870130\n",
       "4  5  0.805195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to count n-grams\n",
    "def count_n_grams(sentences, n):\n",
    "    n_grams = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence)\n",
    "        for i in range(sentence_length - n + 1):\n",
    "            n_gram = tuple(sentence[i:i + n])\n",
    "            n_grams[n_gram] += 1\n",
    "    return n_grams\n",
    "\n",
    "# Function to get suggestions based on n-grams\n",
    "def get_suggestions(previous_tokens, n_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    suggestions = []\n",
    "    n = len(next(iter(n_gram_counts.keys())))\n",
    "    previous_tokens_tuple = tuple(previous_tokens[-(n-1):])\n",
    "    for n_gram, count in n_gram_counts.items():\n",
    "        if len(n_gram) == n and previous_tokens_tuple == tuple(n_gram[:-1]):\n",
    "            if start_with is None or n_gram[-1].startswith(start_with):\n",
    "                suggestions.append(n_gram[-1])\n",
    "    return suggestions\n",
    "\n",
    "# Function to evaluate accuracy\n",
    "def evaluate_accuracy(n_gram_counts, test_data):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for sentence in test_data:\n",
    "        for i in range(len(sentence) - 1):\n",
    "            context = tuple(sentence[:i+1])\n",
    "            true_next_word = sentence[i+1]\n",
    "            \n",
    "            suggestions = get_suggestions(list(context), n_gram_counts, vocabulary, k=1.0)\n",
    "            if true_next_word in suggestions:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Load data from file\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip().split() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "# Path to the dataset\n",
    "file_path = 'C:\\\\Users\\\\Bindu\\\\Documents\\\\NLP\\\\twitter.txt'\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = load_data(file_path)\n",
    "\n",
    "# Use only the first 5 sentences for testing\n",
    "subset_data = data[:5]\n",
    "\n",
    "# Generate n-gram counts for different n\n",
    "n_gram_counts_list = []\n",
    "for n in range(1, 6):  # Example for n=1 to n=5\n",
    "    print(f\"Generating n-gram counts for n = {n}...\")\n",
    "    n_gram_counts = count_n_grams(subset_data, n)\n",
    "    n_gram_counts_list.append(n_gram_counts)\n",
    "\n",
    "# Generate vocabulary\n",
    "vocabulary = list(set([word for sentence in subset_data for word in sentence]))\n",
    "\n",
    "# Evaluate each n-gram model\n",
    "accuracy_results = []\n",
    "for n, n_gram_counts in enumerate(n_gram_counts_list, start=1):\n",
    "    print(f\"Evaluating accuracy for n-gram model with n = {n}...\")\n",
    "    accuracy = evaluate_accuracy(n_gram_counts, subset_data)\n",
    "    accuracy_results.append({'n': n, 'Accuracy': accuracy})\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "display(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating n-gram counts for n = 1...\n",
      "Generating n-gram counts for n = 2...\n",
      "Generating n-gram counts for n = 3...\n",
      "Generating n-gram counts for n = 4...\n",
      "Generating n-gram counts for n = 5...\n",
      "\n",
      "Evaluating accuracy for n-gram model with n = 1...\n",
      "\n",
      "Evaluating sentence: How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.\n",
      "Context: ('How',), True Next Word: are, Suggestions: []\n",
      "Context: ('How', 'are'), True Next Word: you?, Suggestions: []\n",
      "Context: ('How', 'are', 'you?'), True Next Word: Btw, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw'), True Next Word: thanks, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks'), True Next Word: for, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for'), True Next Word: the, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the'), True Next Word: RT., Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.'), True Next Word: You, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You'), True Next Word: gonna, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna'), True Next Word: be, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be'), True Next Word: in, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in'), True Next Word: DC, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC'), True Next Word: anytime, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime'), True Next Word: soon?, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?'), True Next Word: Love, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love'), True Next Word: to, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to'), True Next Word: see, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see'), True Next Word: you., Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.'), True Next Word: Been, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been'), True Next Word: way,, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,'), True Next Word: way, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way'), True Next Word: too, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way', 'too'), True Next Word: long., Suggestions: []\n",
      "\n",
      "Evaluating sentence: When you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason.\n",
      "Context: ('When',), True Next Word: you, Suggestions: []\n",
      "Context: ('When', 'you'), True Next Word: meet, Suggestions: []\n",
      "Context: ('When', 'you', 'meet'), True Next Word: someone, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone'), True Next Word: special..., Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...'), True Next Word: you'll, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\"), True Next Word: know., Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.'), True Next Word: Your, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your'), True Next Word: heart, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart'), True Next Word: will, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will'), True Next Word: beat, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat'), True Next Word: more, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more'), True Next Word: rapidly, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly'), True Next Word: and, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and'), True Next Word: you'll, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\"), True Next Word: smile, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile'), True Next Word: for, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for'), True Next Word: no, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for', 'no'), True Next Word: reason., Suggestions: []\n",
      "\n",
      "Evaluating sentence: they've decided its more fun if I don't.\n",
      "Context: (\"they've\",), True Next Word: decided, Suggestions: []\n",
      "Context: (\"they've\", 'decided'), True Next Word: its, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its'), True Next Word: more, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its', 'more'), True Next Word: fun, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun'), True Next Word: if, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if'), True Next Word: I, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if', 'I'), True Next Word: don't., Suggestions: []\n",
      "\n",
      "Evaluating sentence: So Tired D; Played Lazer Tag & Ran A LOT D; Ughh Going To Sleep Like In 5 Minutes ;)\n",
      "Context: ('So',), True Next Word: Tired, Suggestions: []\n",
      "Context: ('So', 'Tired'), True Next Word: D;, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;'), True Next Word: Played, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played'), True Next Word: Lazer, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer'), True Next Word: Tag, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag'), True Next Word: &, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&'), True Next Word: Ran, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran'), True Next Word: A, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A'), True Next Word: LOT, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT'), True Next Word: D;, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;'), True Next Word: Ughh, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh'), True Next Word: Going, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going'), True Next Word: To, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To'), True Next Word: Sleep, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep'), True Next Word: Like, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like'), True Next Word: In, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In'), True Next Word: 5, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5'), True Next Word: Minutes, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5', 'Minutes'), True Next Word: ;), Suggestions: []\n",
      "\n",
      "Evaluating sentence: Words from a complete stranger! Made my birthday even better :)\n",
      "Context: ('Words',), True Next Word: from, Suggestions: []\n",
      "Context: ('Words', 'from'), True Next Word: a, Suggestions: []\n",
      "Context: ('Words', 'from', 'a'), True Next Word: complete, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete'), True Next Word: stranger!, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!'), True Next Word: Made, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made'), True Next Word: my, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my'), True Next Word: birthday, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday'), True Next Word: even, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even'), True Next Word: better, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even', 'better'), True Next Word: :), Suggestions: []\n",
      "\n",
      "Evaluating accuracy for n-gram model with n = 2...\n",
      "\n",
      "Evaluating sentence: How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.\n",
      "Context: ('How',), True Next Word: are, Suggestions: ['are']\n",
      "Context: ('How', 'are'), True Next Word: you?, Suggestions: ['you?']\n",
      "Context: ('How', 'are', 'you?'), True Next Word: Btw, Suggestions: ['Btw']\n",
      "Context: ('How', 'are', 'you?', 'Btw'), True Next Word: thanks, Suggestions: ['thanks']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for'), True Next Word: the, Suggestions: ['the', 'no']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the'), True Next Word: RT., Suggestions: ['RT.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.'), True Next Word: You, Suggestions: ['You']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You'), True Next Word: gonna, Suggestions: ['gonna']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna'), True Next Word: be, Suggestions: ['be']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be'), True Next Word: in, Suggestions: ['in']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in'), True Next Word: DC, Suggestions: ['DC']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC'), True Next Word: anytime, Suggestions: ['anytime']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime'), True Next Word: soon?, Suggestions: ['soon?']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?'), True Next Word: Love, Suggestions: ['Love']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love'), True Next Word: to, Suggestions: ['to']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to'), True Next Word: see, Suggestions: ['see']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see'), True Next Word: you., Suggestions: ['you.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.'), True Next Word: Been, Suggestions: ['Been']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been'), True Next Word: way,, Suggestions: ['way,']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,'), True Next Word: way, Suggestions: ['way']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way'), True Next Word: too, Suggestions: ['too']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way', 'too'), True Next Word: long., Suggestions: ['long.']\n",
      "\n",
      "Evaluating sentence: When you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason.\n",
      "Context: ('When',), True Next Word: you, Suggestions: ['you']\n",
      "Context: ('When', 'you'), True Next Word: meet, Suggestions: ['meet']\n",
      "Context: ('When', 'you', 'meet'), True Next Word: someone, Suggestions: ['someone']\n",
      "Context: ('When', 'you', 'meet', 'someone'), True Next Word: special..., Suggestions: ['special...']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\"), True Next Word: know., Suggestions: ['know.', 'smile']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.'), True Next Word: Your, Suggestions: ['Your']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your'), True Next Word: heart, Suggestions: ['heart']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart'), True Next Word: will, Suggestions: ['will']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will'), True Next Word: beat, Suggestions: ['beat']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat'), True Next Word: more, Suggestions: ['more']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more'), True Next Word: rapidly, Suggestions: ['rapidly', 'fun']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly'), True Next Word: and, Suggestions: ['and']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\"), True Next Word: smile, Suggestions: ['know.', 'smile']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for'), True Next Word: no, Suggestions: ['the', 'no']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for', 'no'), True Next Word: reason., Suggestions: ['reason.']\n",
      "\n",
      "Evaluating sentence: they've decided its more fun if I don't.\n",
      "Context: (\"they've\",), True Next Word: decided, Suggestions: ['decided']\n",
      "Context: (\"they've\", 'decided'), True Next Word: its, Suggestions: ['its']\n",
      "Context: (\"they've\", 'decided', 'its'), True Next Word: more, Suggestions: ['more']\n",
      "Context: (\"they've\", 'decided', 'its', 'more'), True Next Word: fun, Suggestions: ['rapidly', 'fun']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun'), True Next Word: if, Suggestions: ['if']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if'), True Next Word: I, Suggestions: ['I']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if', 'I'), True Next Word: don't., Suggestions: [\"don't.\"]\n",
      "\n",
      "Evaluating sentence: So Tired D; Played Lazer Tag & Ran A LOT D; Ughh Going To Sleep Like In 5 Minutes ;)\n",
      "Context: ('So',), True Next Word: Tired, Suggestions: ['Tired']\n",
      "Context: ('So', 'Tired'), True Next Word: D;, Suggestions: ['D;']\n",
      "Context: ('So', 'Tired', 'D;'), True Next Word: Played, Suggestions: ['Played', 'Ughh']\n",
      "Context: ('So', 'Tired', 'D;', 'Played'), True Next Word: Lazer, Suggestions: ['Lazer']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer'), True Next Word: Tag, Suggestions: ['Tag']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag'), True Next Word: &, Suggestions: ['&']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&'), True Next Word: Ran, Suggestions: ['Ran']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran'), True Next Word: A, Suggestions: ['A']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A'), True Next Word: LOT, Suggestions: ['LOT']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT'), True Next Word: D;, Suggestions: ['D;']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;'), True Next Word: Ughh, Suggestions: ['Played', 'Ughh']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh'), True Next Word: Going, Suggestions: ['Going']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going'), True Next Word: To, Suggestions: ['To']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To'), True Next Word: Sleep, Suggestions: ['Sleep']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep'), True Next Word: Like, Suggestions: ['Like']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like'), True Next Word: In, Suggestions: ['In']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In'), True Next Word: 5, Suggestions: ['5']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5'), True Next Word: Minutes, Suggestions: ['Minutes']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5', 'Minutes'), True Next Word: ;), Suggestions: [';)']\n",
      "\n",
      "Evaluating sentence: Words from a complete stranger! Made my birthday even better :)\n",
      "Context: ('Words',), True Next Word: from, Suggestions: ['from']\n",
      "Context: ('Words', 'from'), True Next Word: a, Suggestions: ['a']\n",
      "Context: ('Words', 'from', 'a'), True Next Word: complete, Suggestions: ['complete']\n",
      "Context: ('Words', 'from', 'a', 'complete'), True Next Word: stranger!, Suggestions: ['stranger!']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!'), True Next Word: Made, Suggestions: ['Made']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made'), True Next Word: my, Suggestions: ['my']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my'), True Next Word: birthday, Suggestions: ['birthday']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday'), True Next Word: even, Suggestions: ['even']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even'), True Next Word: better, Suggestions: ['better']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even', 'better'), True Next Word: :), Suggestions: [':)']\n",
      "\n",
      "Evaluating accuracy for n-gram model with n = 3...\n",
      "\n",
      "Evaluating sentence: How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.\n",
      "Context: ('How',), True Next Word: are, Suggestions: []\n",
      "Context: ('How', 'are'), True Next Word: you?, Suggestions: ['you?']\n",
      "Context: ('How', 'are', 'you?'), True Next Word: Btw, Suggestions: ['Btw']\n",
      "Context: ('How', 'are', 'you?', 'Btw'), True Next Word: thanks, Suggestions: ['thanks']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for'), True Next Word: the, Suggestions: ['the']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the'), True Next Word: RT., Suggestions: ['RT.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.'), True Next Word: You, Suggestions: ['You']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You'), True Next Word: gonna, Suggestions: ['gonna']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna'), True Next Word: be, Suggestions: ['be']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be'), True Next Word: in, Suggestions: ['in']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in'), True Next Word: DC, Suggestions: ['DC']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC'), True Next Word: anytime, Suggestions: ['anytime']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime'), True Next Word: soon?, Suggestions: ['soon?']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?'), True Next Word: Love, Suggestions: ['Love']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love'), True Next Word: to, Suggestions: ['to']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to'), True Next Word: see, Suggestions: ['see']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see'), True Next Word: you., Suggestions: ['you.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.'), True Next Word: Been, Suggestions: ['Been']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been'), True Next Word: way,, Suggestions: ['way,']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,'), True Next Word: way, Suggestions: ['way']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way'), True Next Word: too, Suggestions: ['too']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way', 'too'), True Next Word: long., Suggestions: ['long.']\n",
      "\n",
      "Evaluating sentence: When you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason.\n",
      "Context: ('When',), True Next Word: you, Suggestions: []\n",
      "Context: ('When', 'you'), True Next Word: meet, Suggestions: ['meet']\n",
      "Context: ('When', 'you', 'meet'), True Next Word: someone, Suggestions: ['someone']\n",
      "Context: ('When', 'you', 'meet', 'someone'), True Next Word: special..., Suggestions: ['special...']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\"), True Next Word: know., Suggestions: ['know.']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.'), True Next Word: Your, Suggestions: ['Your']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your'), True Next Word: heart, Suggestions: ['heart']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart'), True Next Word: will, Suggestions: ['will']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will'), True Next Word: beat, Suggestions: ['beat']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat'), True Next Word: more, Suggestions: ['more']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more'), True Next Word: rapidly, Suggestions: ['rapidly']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly'), True Next Word: and, Suggestions: ['and']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\"), True Next Word: smile, Suggestions: ['smile']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for'), True Next Word: no, Suggestions: ['no']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for', 'no'), True Next Word: reason., Suggestions: ['reason.']\n",
      "\n",
      "Evaluating sentence: they've decided its more fun if I don't.\n",
      "Context: (\"they've\",), True Next Word: decided, Suggestions: []\n",
      "Context: (\"they've\", 'decided'), True Next Word: its, Suggestions: ['its']\n",
      "Context: (\"they've\", 'decided', 'its'), True Next Word: more, Suggestions: ['more']\n",
      "Context: (\"they've\", 'decided', 'its', 'more'), True Next Word: fun, Suggestions: ['fun']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun'), True Next Word: if, Suggestions: ['if']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if'), True Next Word: I, Suggestions: ['I']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if', 'I'), True Next Word: don't., Suggestions: [\"don't.\"]\n",
      "\n",
      "Evaluating sentence: So Tired D; Played Lazer Tag & Ran A LOT D; Ughh Going To Sleep Like In 5 Minutes ;)\n",
      "Context: ('So',), True Next Word: Tired, Suggestions: []\n",
      "Context: ('So', 'Tired'), True Next Word: D;, Suggestions: ['D;']\n",
      "Context: ('So', 'Tired', 'D;'), True Next Word: Played, Suggestions: ['Played']\n",
      "Context: ('So', 'Tired', 'D;', 'Played'), True Next Word: Lazer, Suggestions: ['Lazer']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer'), True Next Word: Tag, Suggestions: ['Tag']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag'), True Next Word: &, Suggestions: ['&']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&'), True Next Word: Ran, Suggestions: ['Ran']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran'), True Next Word: A, Suggestions: ['A']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A'), True Next Word: LOT, Suggestions: ['LOT']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT'), True Next Word: D;, Suggestions: ['D;']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;'), True Next Word: Ughh, Suggestions: ['Ughh']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh'), True Next Word: Going, Suggestions: ['Going']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going'), True Next Word: To, Suggestions: ['To']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To'), True Next Word: Sleep, Suggestions: ['Sleep']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep'), True Next Word: Like, Suggestions: ['Like']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like'), True Next Word: In, Suggestions: ['In']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In'), True Next Word: 5, Suggestions: ['5']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5'), True Next Word: Minutes, Suggestions: ['Minutes']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5', 'Minutes'), True Next Word: ;), Suggestions: [';)']\n",
      "\n",
      "Evaluating sentence: Words from a complete stranger! Made my birthday even better :)\n",
      "Context: ('Words',), True Next Word: from, Suggestions: []\n",
      "Context: ('Words', 'from'), True Next Word: a, Suggestions: ['a']\n",
      "Context: ('Words', 'from', 'a'), True Next Word: complete, Suggestions: ['complete']\n",
      "Context: ('Words', 'from', 'a', 'complete'), True Next Word: stranger!, Suggestions: ['stranger!']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!'), True Next Word: Made, Suggestions: ['Made']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made'), True Next Word: my, Suggestions: ['my']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my'), True Next Word: birthday, Suggestions: ['birthday']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday'), True Next Word: even, Suggestions: ['even']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even'), True Next Word: better, Suggestions: ['better']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even', 'better'), True Next Word: :), Suggestions: [':)']\n",
      "\n",
      "Evaluating accuracy for n-gram model with n = 4...\n",
      "\n",
      "Evaluating sentence: How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.\n",
      "Context: ('How',), True Next Word: are, Suggestions: []\n",
      "Context: ('How', 'are'), True Next Word: you?, Suggestions: []\n",
      "Context: ('How', 'are', 'you?'), True Next Word: Btw, Suggestions: ['Btw']\n",
      "Context: ('How', 'are', 'you?', 'Btw'), True Next Word: thanks, Suggestions: ['thanks']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for'), True Next Word: the, Suggestions: ['the']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the'), True Next Word: RT., Suggestions: ['RT.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.'), True Next Word: You, Suggestions: ['You']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You'), True Next Word: gonna, Suggestions: ['gonna']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna'), True Next Word: be, Suggestions: ['be']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be'), True Next Word: in, Suggestions: ['in']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in'), True Next Word: DC, Suggestions: ['DC']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC'), True Next Word: anytime, Suggestions: ['anytime']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime'), True Next Word: soon?, Suggestions: ['soon?']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?'), True Next Word: Love, Suggestions: ['Love']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love'), True Next Word: to, Suggestions: ['to']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to'), True Next Word: see, Suggestions: ['see']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see'), True Next Word: you., Suggestions: ['you.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.'), True Next Word: Been, Suggestions: ['Been']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been'), True Next Word: way,, Suggestions: ['way,']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,'), True Next Word: way, Suggestions: ['way']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way'), True Next Word: too, Suggestions: ['too']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way', 'too'), True Next Word: long., Suggestions: ['long.']\n",
      "\n",
      "Evaluating sentence: When you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason.\n",
      "Context: ('When',), True Next Word: you, Suggestions: []\n",
      "Context: ('When', 'you'), True Next Word: meet, Suggestions: []\n",
      "Context: ('When', 'you', 'meet'), True Next Word: someone, Suggestions: ['someone']\n",
      "Context: ('When', 'you', 'meet', 'someone'), True Next Word: special..., Suggestions: ['special...']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\"), True Next Word: know., Suggestions: ['know.']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.'), True Next Word: Your, Suggestions: ['Your']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your'), True Next Word: heart, Suggestions: ['heart']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart'), True Next Word: will, Suggestions: ['will']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will'), True Next Word: beat, Suggestions: ['beat']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat'), True Next Word: more, Suggestions: ['more']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more'), True Next Word: rapidly, Suggestions: ['rapidly']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly'), True Next Word: and, Suggestions: ['and']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\"), True Next Word: smile, Suggestions: ['smile']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for'), True Next Word: no, Suggestions: ['no']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for', 'no'), True Next Word: reason., Suggestions: ['reason.']\n",
      "\n",
      "Evaluating sentence: they've decided its more fun if I don't.\n",
      "Context: (\"they've\",), True Next Word: decided, Suggestions: []\n",
      "Context: (\"they've\", 'decided'), True Next Word: its, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its'), True Next Word: more, Suggestions: ['more']\n",
      "Context: (\"they've\", 'decided', 'its', 'more'), True Next Word: fun, Suggestions: ['fun']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun'), True Next Word: if, Suggestions: ['if']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if'), True Next Word: I, Suggestions: ['I']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if', 'I'), True Next Word: don't., Suggestions: [\"don't.\"]\n",
      "\n",
      "Evaluating sentence: So Tired D; Played Lazer Tag & Ran A LOT D; Ughh Going To Sleep Like In 5 Minutes ;)\n",
      "Context: ('So',), True Next Word: Tired, Suggestions: []\n",
      "Context: ('So', 'Tired'), True Next Word: D;, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;'), True Next Word: Played, Suggestions: ['Played']\n",
      "Context: ('So', 'Tired', 'D;', 'Played'), True Next Word: Lazer, Suggestions: ['Lazer']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer'), True Next Word: Tag, Suggestions: ['Tag']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag'), True Next Word: &, Suggestions: ['&']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&'), True Next Word: Ran, Suggestions: ['Ran']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran'), True Next Word: A, Suggestions: ['A']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A'), True Next Word: LOT, Suggestions: ['LOT']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT'), True Next Word: D;, Suggestions: ['D;']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;'), True Next Word: Ughh, Suggestions: ['Ughh']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh'), True Next Word: Going, Suggestions: ['Going']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going'), True Next Word: To, Suggestions: ['To']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To'), True Next Word: Sleep, Suggestions: ['Sleep']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep'), True Next Word: Like, Suggestions: ['Like']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like'), True Next Word: In, Suggestions: ['In']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In'), True Next Word: 5, Suggestions: ['5']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5'), True Next Word: Minutes, Suggestions: ['Minutes']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5', 'Minutes'), True Next Word: ;), Suggestions: [';)']\n",
      "\n",
      "Evaluating sentence: Words from a complete stranger! Made my birthday even better :)\n",
      "Context: ('Words',), True Next Word: from, Suggestions: []\n",
      "Context: ('Words', 'from'), True Next Word: a, Suggestions: []\n",
      "Context: ('Words', 'from', 'a'), True Next Word: complete, Suggestions: ['complete']\n",
      "Context: ('Words', 'from', 'a', 'complete'), True Next Word: stranger!, Suggestions: ['stranger!']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!'), True Next Word: Made, Suggestions: ['Made']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made'), True Next Word: my, Suggestions: ['my']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my'), True Next Word: birthday, Suggestions: ['birthday']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday'), True Next Word: even, Suggestions: ['even']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even'), True Next Word: better, Suggestions: ['better']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even', 'better'), True Next Word: :), Suggestions: [':)']\n",
      "\n",
      "Evaluating accuracy for n-gram model with n = 5...\n",
      "\n",
      "Evaluating sentence: How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.\n",
      "Context: ('How',), True Next Word: are, Suggestions: []\n",
      "Context: ('How', 'are'), True Next Word: you?, Suggestions: []\n",
      "Context: ('How', 'are', 'you?'), True Next Word: Btw, Suggestions: []\n",
      "Context: ('How', 'are', 'you?', 'Btw'), True Next Word: thanks, Suggestions: ['thanks']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for'), True Next Word: the, Suggestions: ['the']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the'), True Next Word: RT., Suggestions: ['RT.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.'), True Next Word: You, Suggestions: ['You']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You'), True Next Word: gonna, Suggestions: ['gonna']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna'), True Next Word: be, Suggestions: ['be']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be'), True Next Word: in, Suggestions: ['in']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in'), True Next Word: DC, Suggestions: ['DC']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC'), True Next Word: anytime, Suggestions: ['anytime']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime'), True Next Word: soon?, Suggestions: ['soon?']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?'), True Next Word: Love, Suggestions: ['Love']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love'), True Next Word: to, Suggestions: ['to']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to'), True Next Word: see, Suggestions: ['see']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see'), True Next Word: you., Suggestions: ['you.']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.'), True Next Word: Been, Suggestions: ['Been']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been'), True Next Word: way,, Suggestions: ['way,']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,'), True Next Word: way, Suggestions: ['way']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way'), True Next Word: too, Suggestions: ['too']\n",
      "Context: ('How', 'are', 'you?', 'Btw', 'thanks', 'for', 'the', 'RT.', 'You', 'gonna', 'be', 'in', 'DC', 'anytime', 'soon?', 'Love', 'to', 'see', 'you.', 'Been', 'way,', 'way', 'too'), True Next Word: long., Suggestions: ['long.']\n",
      "\n",
      "Evaluating sentence: When you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason.\n",
      "Context: ('When',), True Next Word: you, Suggestions: []\n",
      "Context: ('When', 'you'), True Next Word: meet, Suggestions: []\n",
      "Context: ('When', 'you', 'meet'), True Next Word: someone, Suggestions: []\n",
      "Context: ('When', 'you', 'meet', 'someone'), True Next Word: special..., Suggestions: ['special...']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\"), True Next Word: know., Suggestions: ['know.']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.'), True Next Word: Your, Suggestions: ['Your']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your'), True Next Word: heart, Suggestions: ['heart']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart'), True Next Word: will, Suggestions: ['will']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will'), True Next Word: beat, Suggestions: ['beat']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat'), True Next Word: more, Suggestions: ['more']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more'), True Next Word: rapidly, Suggestions: ['rapidly']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly'), True Next Word: and, Suggestions: ['and']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and'), True Next Word: you'll, Suggestions: [\"you'll\"]\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\"), True Next Word: smile, Suggestions: ['smile']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile'), True Next Word: for, Suggestions: ['for']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for'), True Next Word: no, Suggestions: ['no']\n",
      "Context: ('When', 'you', 'meet', 'someone', 'special...', \"you'll\", 'know.', 'Your', 'heart', 'will', 'beat', 'more', 'rapidly', 'and', \"you'll\", 'smile', 'for', 'no'), True Next Word: reason., Suggestions: ['reason.']\n",
      "\n",
      "Evaluating sentence: they've decided its more fun if I don't.\n",
      "Context: (\"they've\",), True Next Word: decided, Suggestions: []\n",
      "Context: (\"they've\", 'decided'), True Next Word: its, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its'), True Next Word: more, Suggestions: []\n",
      "Context: (\"they've\", 'decided', 'its', 'more'), True Next Word: fun, Suggestions: ['fun']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun'), True Next Word: if, Suggestions: ['if']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if'), True Next Word: I, Suggestions: ['I']\n",
      "Context: (\"they've\", 'decided', 'its', 'more', 'fun', 'if', 'I'), True Next Word: don't., Suggestions: [\"don't.\"]\n",
      "\n",
      "Evaluating sentence: So Tired D; Played Lazer Tag & Ran A LOT D; Ughh Going To Sleep Like In 5 Minutes ;)\n",
      "Context: ('So',), True Next Word: Tired, Suggestions: []\n",
      "Context: ('So', 'Tired'), True Next Word: D;, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;'), True Next Word: Played, Suggestions: []\n",
      "Context: ('So', 'Tired', 'D;', 'Played'), True Next Word: Lazer, Suggestions: ['Lazer']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer'), True Next Word: Tag, Suggestions: ['Tag']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag'), True Next Word: &, Suggestions: ['&']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&'), True Next Word: Ran, Suggestions: ['Ran']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran'), True Next Word: A, Suggestions: ['A']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A'), True Next Word: LOT, Suggestions: ['LOT']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT'), True Next Word: D;, Suggestions: ['D;']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;'), True Next Word: Ughh, Suggestions: ['Ughh']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh'), True Next Word: Going, Suggestions: ['Going']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going'), True Next Word: To, Suggestions: ['To']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To'), True Next Word: Sleep, Suggestions: ['Sleep']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep'), True Next Word: Like, Suggestions: ['Like']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like'), True Next Word: In, Suggestions: ['In']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In'), True Next Word: 5, Suggestions: ['5']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5'), True Next Word: Minutes, Suggestions: ['Minutes']\n",
      "Context: ('So', 'Tired', 'D;', 'Played', 'Lazer', 'Tag', '&', 'Ran', 'A', 'LOT', 'D;', 'Ughh', 'Going', 'To', 'Sleep', 'Like', 'In', '5', 'Minutes'), True Next Word: ;), Suggestions: [';)']\n",
      "\n",
      "Evaluating sentence: Words from a complete stranger! Made my birthday even better :)\n",
      "Context: ('Words',), True Next Word: from, Suggestions: []\n",
      "Context: ('Words', 'from'), True Next Word: a, Suggestions: []\n",
      "Context: ('Words', 'from', 'a'), True Next Word: complete, Suggestions: []\n",
      "Context: ('Words', 'from', 'a', 'complete'), True Next Word: stranger!, Suggestions: ['stranger!']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!'), True Next Word: Made, Suggestions: ['Made']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made'), True Next Word: my, Suggestions: ['my']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my'), True Next Word: birthday, Suggestions: ['birthday']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday'), True Next Word: even, Suggestions: ['even']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even'), True Next Word: better, Suggestions: ['better']\n",
      "Context: ('Words', 'from', 'a', 'complete', 'stranger!', 'Made', 'my', 'birthday', 'even', 'better'), True Next Word: :), Suggestions: [':)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.935065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.870130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  Accuracy\n",
       "0  1  0.000000\n",
       "1  2  1.000000\n",
       "2  3  0.935065\n",
       "3  4  0.870130\n",
       "4  5  0.805195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to count n-grams\n",
    "def count_n_grams(sentences, n):\n",
    "    n_grams = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence)\n",
    "        for i in range(sentence_length - n + 1):\n",
    "            n_gram = tuple(sentence[i:i + n])\n",
    "            n_grams[n_gram] += 1\n",
    "    return n_grams\n",
    "\n",
    "# Function to get suggestions based on n-grams\n",
    "def get_suggestions(previous_tokens, n_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    suggestions = []\n",
    "    n = len(next(iter(n_gram_counts.keys())))\n",
    "    previous_tokens_tuple = tuple(previous_tokens[-(n-1):])\n",
    "    for n_gram, count in n_gram_counts.items():\n",
    "        if len(n_gram) == n and previous_tokens_tuple == tuple(n_gram[:-1]):\n",
    "            if start_with is None or n_gram[-1].startswith(start_with):\n",
    "                suggestions.append(n_gram[-1])\n",
    "    return suggestions\n",
    "\n",
    "# Function to evaluate accuracy\n",
    "def evaluate_accuracy(n_gram_counts, test_data):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for sentence in test_data:\n",
    "        print(f\"\\nEvaluating sentence: {' '.join(sentence)}\")\n",
    "        for i in range(len(sentence) - 1):\n",
    "            context = tuple(sentence[:i+1])\n",
    "            true_next_word = sentence[i+1]\n",
    "            \n",
    "            suggestions = get_suggestions(list(context), n_gram_counts, vocabulary, k=1.0)\n",
    "            print(f\"Context: {context}, True Next Word: {true_next_word}, Suggestions: {suggestions}\")\n",
    "            \n",
    "            if true_next_word in suggestions:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Load data from file\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip().split() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "# Path to the dataset\n",
    "file_path = 'C:\\\\Users\\\\Bindu\\\\Documents\\\\NLP\\\\twitter.txt'\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = load_data(file_path)\n",
    "\n",
    "# Use only the first 5 sentences for testing\n",
    "subset_data = data[:5]\n",
    "\n",
    "# Generate n-gram counts for different n\n",
    "n_gram_counts_list = []\n",
    "for n in range(1, 6):  # Example for n=1 to n=5\n",
    "    print(f\"Generating n-gram counts for n = {n}...\")\n",
    "    n_gram_counts = count_n_grams(subset_data, n)\n",
    "    n_gram_counts_list.append(n_gram_counts)\n",
    "\n",
    "# Generate vocabulary\n",
    "vocabulary = list(set([word for sentence in subset_data for word in sentence]))\n",
    "\n",
    "# Evaluate each n-gram model\n",
    "accuracy_results = []\n",
    "for n, n_gram_counts in enumerate(n_gram_counts_list, start=1):\n",
    "    print(f\"\\nEvaluating accuracy for n-gram model with n = {n}...\")\n",
    "    accuracy = evaluate_accuracy(n_gram_counts, subset_data)\n",
    "    accuracy_results.append({'n': n, 'Accuracy': accuracy})\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "display(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>1-gram Accuracy</th>\n",
       "      <th>2-gram Accuracy</th>\n",
       "      <th>3-gram Accuracy</th>\n",
       "      <th>4-gram Accuracy</th>\n",
       "      <th>5-gram Accuracy</th>\n",
       "      <th>Best N-gram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How are you? Btw thanks for the RT. You gonna ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>2-gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When you meet someone special... you'll know. ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2-gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they've decided its more fun if I don't.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2-gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So Tired D; Played Lazer Tag &amp; Ran A LOT D; Ug...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>2-gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Words from a complete stranger! Made my birthd...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2-gram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  1-gram Accuracy  \\\n",
       "0  How are you? Btw thanks for the RT. You gonna ...              0.0   \n",
       "1  When you meet someone special... you'll know. ...              0.0   \n",
       "2           they've decided its more fun if I don't.              0.0   \n",
       "3  So Tired D; Played Lazer Tag & Ran A LOT D; Ug...              0.0   \n",
       "4  Words from a complete stranger! Made my birthd...              0.0   \n",
       "\n",
       "   2-gram Accuracy  3-gram Accuracy  4-gram Accuracy  5-gram Accuracy  \\\n",
       "0              1.0         0.956522         0.913043         0.869565   \n",
       "1              1.0         0.944444         0.888889         0.833333   \n",
       "2              1.0         0.857143         0.714286         0.571429   \n",
       "3              1.0         0.947368         0.894737         0.842105   \n",
       "4              1.0         0.900000         0.800000         0.700000   \n",
       "\n",
       "  Best N-gram  \n",
       "0      2-gram  \n",
       "1      2-gram  \n",
       "2      2-gram  \n",
       "3      2-gram  \n",
       "4      2-gram  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to count n-grams\n",
    "def count_n_grams(sentences, n):\n",
    "    n_grams = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence)\n",
    "        for i in range(sentence_length - n + 1):\n",
    "            n_gram = tuple(sentence[i:i + n])\n",
    "            n_grams[n_gram] += 1\n",
    "    return n_grams\n",
    "\n",
    "# Dummy implementation of get_suggestions function\n",
    "def get_suggestions(previous_tokens, n_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    # Generate suggestions based on the most frequent n-gram that matches the context\n",
    "    suggestions = []\n",
    "    n = len(next(iter(n_gram_counts.keys())))\n",
    "    previous_tokens_tuple = tuple(previous_tokens[-(n-1):])\n",
    "    candidates = {n_gram[-1]: count for n_gram, count in n_gram_counts.items() if n_gram[:-1] == previous_tokens_tuple}\n",
    "    sorted_candidates = sorted(candidates.items(), key=lambda x: x[1], reverse=True)\n",
    "    suggestions = [word for word, _ in sorted_candidates]\n",
    "    return suggestions[:3]  # Return top 3 suggestions for simplicity\n",
    "\n",
    "# Function to evaluate accuracy\n",
    "def evaluate_accuracy(n_gram_counts, test_data):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for sentence in test_data:\n",
    "        for i in range(len(sentence) - 1):\n",
    "            context = tuple(sentence[:i+1])\n",
    "            true_next_word = sentence[i+1]\n",
    "            \n",
    "            suggestions = get_suggestions(list(context), n_gram_counts, vocabulary, k=1.0)\n",
    "            \n",
    "            if true_next_word in suggestions:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Load data from file\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip().split() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "# Path to the dataset\n",
    "file_path = 'C:\\\\Users\\\\Bindu\\\\Documents\\\\NLP\\\\twitter.txt'\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = load_data(file_path)\n",
    "\n",
    "# Use only the first 5 sentences for testing\n",
    "subset_data = data[:5]\n",
    "\n",
    "# Generate vocabulary\n",
    "vocabulary = list(set([word for sentence in subset_data for word in sentence]))\n",
    "\n",
    "# Generate n-gram counts for different n\n",
    "n_gram_counts_list = []\n",
    "for n in range(1, 6):  # Example for n=1 to n=5\n",
    "    n_gram_counts = count_n_grams(subset_data, n)\n",
    "    n_gram_counts_list.append(n_gram_counts)\n",
    "\n",
    "# Evaluate each n-gram model and store results\n",
    "results = []\n",
    "\n",
    "for idx, sentence in enumerate(subset_data):\n",
    "    sentence_result = {'Sentence': ' '.join(sentence)}\n",
    "    best_accuracy = 0\n",
    "    best_n = 0\n",
    "    \n",
    "    for n, n_gram_counts in enumerate(n_gram_counts_list, start=1):\n",
    "        accuracy = evaluate_accuracy(n_gram_counts, [sentence])\n",
    "        sentence_result[f'{n}-gram Accuracy'] = accuracy\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_n = n\n",
    "    \n",
    "    sentence_result['Best N-gram'] = f'{best_n}-gram' if best_n > 0 else 'None'\n",
    "    results.append(sentence_result)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "accuracy_df = pd.DataFrame(results)\n",
    "display(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
